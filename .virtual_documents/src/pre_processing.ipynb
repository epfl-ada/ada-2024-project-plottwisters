





import pandas as pd
import numpy as np
import re
import matplotlib.pyplot as plt
from bs4 import BeautifulSoup 
from datetime import datetime





DATA_FOLDER = '../data/'
CHARACTER_METADATA_DATASET = DATA_FOLDER+"character.metadata.tsv"
MOVIE_METADATA_DATASET = DATA_FOLDER+"movie.metadata.tsv"
EVENT_CODE = DATA_FOLDER+"data_events.txt"
PLOT_SUMMARIES = DATA_FOLDER+"plot_summaries.txt"

column_names_character = [
    'Wikipedia movie ID',
    'Freebase movie ID',
    'Movie release date',
    'Character name',
    'Actor date of birth',
    'Actor gender',
    'Actor height (in meters)',
    'Actor ethnicity (Freebase ID)',
    'Actor name',
    'Actor age at movie release',
    'Freebase character/actor map ID',
    'Freebase character ID',
    'Freebase actor ID'
]

column_names_movie = [
    'Wikipedia movie ID',
    'Freebase movie ID',
    'Movie name',
    'Movie release date',
    'Movie box office revenue',
    'Movie runtime',
    'Movie languages',
    'Movie countries',
    'Movie genres'
]
df_character=pd.read_csv(CHARACTER_METADATA_DATASET, sep='\t', names = column_names_character)
df_movie=pd.read_csv(MOVIE_METADATA_DATASET, sep='\t', names = column_names_movie)
with open(EVENT_CODE, encoding='utf-8') as file:
    html_code = file.read()







# Columns we will use for our project
df = df_movie[['Wikipedia movie ID', 'Movie name', 'Movie release date','Movie box office revenue','Movie runtime','Movie languages','Movie countries','Movie genres']] # and themes to add
df.set_index('Wikipedia movie ID', inplace=True)

df.head(5)


is_unique = df.index.is_unique
print("Is the index unique?", is_unique)


df.dtypes
df.info()








#Issue: Many movies lack a complete release date (day and month), and some are missing a release date entirely.
#Solution: Create two new columnsâ€”one for the "year" and another for the full "year-month-day" format, with NaN values for missing information.

df_treated = df.copy()
df_treated['Movie release year'] = df_treated['Movie release date'].str[:4].astype('Int32') #7k nans


cols = list(df_treated.columns)
cols.insert(1, cols.pop(cols.index('Movie release year')))
df_treated = df_treated[cols]

df_treated['Movie release date'] = pd.to_datetime(df_treated['Movie release date'], errors='coerce') #42k nans
df_treated['Movie release month'] = df_treated['Movie release date'].dt.strftime('%m').astype('Int32')

print(df_treated['Movie release date'].isna().sum())
print(df_treated['Movie release year'].isna().sum())
print(df_treated['Movie release month'].isna().sum())

cols = list(df_treated.columns)
cols.insert(1, cols.pop(cols.index('Movie release month')))
df_treated = df_treated[cols]
df_treated.head(5) 


df_treated.shape


df_treated.dtypes






df_plot = df_treated.dropna(subset=['Movie release year', 'Movie box office revenue'])
average_revenue_per_year = df_plot.groupby('Movie release year')['Movie box office revenue'].mean()
plt.figure(figsize=(10, 6))
plt.plot(average_revenue_per_year[1:].index, average_revenue_per_year[1:].values)
plt.xlabel("Movie Release Year")
plt.ylabel("Average Box Office Revenue")
plt.title("Average Box Office Revenue by Movie Release Year")
plt.show()



#Box office values are difficult to compare across different years due to inflation and varying years of measurement.
#Adjust all (USD) box office revenues that are not NaN to 2024 values using known US inflation rates, enabling consistent comparisons.
inflation_data = {
    1914: 1.3, 1915: 0.9, 1916: 7.7, 1917: 17.8, 1918: 17.3, 
    1919: 15.2, 1920: 15.6, 1921: -10.9, 1922: -6.2, 1923: 1.8, 
    1924: 0.4, 1925: 2.4, 1926: 0.9, 1927: -1.9, 1928: -1.2, 
    1929: 0.0, 1930: -2.7, 1931: -8.9, 1932: -10.3, 1933: -5.2, 
    1934: 3.5, 1935: 2.6, 1936: 1.0, 1937: 3.7, 1938: -2.0, 
    1939: -1.3, 1940: 0.7, 1941: 5.1, 1942: 10.9, 1943: 6.0, 
    1944: 1.6, 1945: 2.3, 1946: 8.5, 1947: 14.4, 1948: 7.7, 
    1949: -1.0, 1950: 1.1, 1951: 7.9, 1952: 2.3, 1953: 0.8, 
    1954: 0.3, 1955: -0.3, 1956: 1.5, 1957: 3.3, 1958: 2.7, 
    1959: 1.08, 1960: 1.5, 1961: 1.1, 1962: 1.2, 1963: 1.2, 
    1964: 1.3, 1965: 1.6, 1966: 3.0, 1967: 2.8, 1968: 4.3, 
    1969: 5.5, 1970: 5.8, 1971: 4.3, 1972: 3.3, 1973: 6.2, 
    1974: 11.1, 1975: 9.1, 1976: 5.7, 1977: 6.5, 1978: 7.6, 
    1979: 11.3, 1980: 13.5, 1981: 10.3, 1982: 6.1, 1983: 3.2, 
    1984: 4.3, 1985: 3.5, 1986: 1.9, 1987: 3.7, 1988: 4.1, 
    1989: 4.8, 1990: 5.4, 1991: 4.2, 1992: 3.0, 1993: 3.0, 
    1994: 2.6, 1995: 2.8, 1996: 2.9, 1997: 2.3, 1998: 1.6, 
    1999: 2.2, 2000: 3.4, 2001: 2.8, 2002: 1.6, 2003: 2.3, 
    2004: 2.7, 2005: 3.4, 2006: 3.2, 2007: 2.9, 2008: 3.8, 
    2009: -0.4, 2010: 1.6, 2011: 3.2, 2012: 2.1, 2013: 1.5, 
    2014: 1.6, 2015: 0.1, 2016: 1.3, 2017: 2.1, 2018: 2.4, 
    2019: 1.8, 2020: 1.2, 2021: 4.7, 2022: 8.0, 2023: 4.1, 2024: 3.2
}

#source : minesota website

def adjust_for_inflation(year, amount, inflation_data):
    """
    Adjusts the given amount from the provided year to 2024 based on annual inflation rates.

    Parameters:
    year (int): The starting year.
    amount (float): The amount to be adjusted.
    inflation_data (dict): A dictionary with years as keys and inflation rates as values.

    Returns:
    float: The inflation-adjusted amount for 2024.
    """
    adjusted_value = amount
    
    for y in range(year, 2024):
        if y in inflation_data:
            inflation_rate = inflation_data[y]
            # Adjust for inflation for each year
            adjusted_value *= (1 + inflation_rate / 100)
    return adjusted_value


for i in range(len(df_treated)):
    if pd.notna(df_treated.iloc[i]['Movie release year']) and pd.notna(df_treated.iloc[i]['Movie box office revenue']):
        release_year = df_treated['Movie release year'].iloc[i]
        
        adjusted_revenue = adjust_for_inflation(release_year, df_treated.iloc[i]['Movie box office revenue'], inflation_data)
        
        df_treated.iloc[i, df_treated.columns.get_loc('Movie box office revenue')] = adjusted_revenue
 
df_treated.head(5)


df_treated.shape





#Issue: These columns contain irregular characters and formatting (e.g., `"/m/02h40lc": "English Language"`).
#Solution: Remove special characters and standardize the entries, providing each movie with a clean list of languages, countries, and genres. When the list is empty it means there is no data available.  
def cleaner(value):
    # Remove `{` and `}`
    value = re.sub(r'[{}]', '', value)
    
    # Extract values after ':' that are in between double quotes
    matches = re.findall(r'":\s*"([^"]+)"', value)
    
    # List of words to remove from each match
    words_to_remove = [" Language", " language", " languages", " Languages","\\u00e0 "]
    
    # Remove unwanted words from each match
    if matches:
        for word in words_to_remove:
            matches = [match.replace(word, "") for match in matches]
        return ', '.join(matches)
    
    return value

def remove_unicode_escapes(value):
    # Remove any Unicode escape sequences like \uXXXX
    return re.sub(r'\\u[0-9a-fA-F]{4}', '', value)

    
df_treated['Movie languages'] = df_treated['Movie languages'].apply(cleaner)
df_treated['Movie languages'] = df_treated['Movie languages'].apply(remove_unicode_escapes)

df_treated.head(5)




df_treated['Movie languages'] = df_treated['Movie languages'].apply(lambda x: x.split(', '))
df_treated.head(5)





#same as for languages
df_treated['Movie genres'] = df_treated['Movie genres'].apply(cleaner)


df_treated['Movie genres'] = df_treated['Movie genres'].apply(lambda x: x.split(', '))
df_treated.head(5)





#same as for languages
df_treated['Movie countries'] = df_treated['Movie countries'].apply(cleaner)



df_treated['Movie countries'] = df_treated['Movie countries'].apply(lambda x: x.split(', '))
df_treated.head(5)





# Get the movie names of the long movies
is_long_movie = df_treated['Movie runtime'] > 10000
long_movies = df_treated.loc[df_treated[is_long_movie].index]
long_movies


# Get the movie names of movies under a second
is_short_movie = df_treated['Movie runtime'] < 0.0166667

short_movies = df_treated.loc[df_treated[is_short_movie].index]
short_movies


highest_runtimes = df_treated['Movie runtime'].nlargest(10)
print("10 highest Movie runtime values:\n", highest_runtimes)

lowest_runtimes = df_treated['Movie runtime'].nsmallest(10)
print("10 lowest Movie runtime values:\n", lowest_runtimes)

lowest_years = df_treated['Movie release year'].nsmallest(10)
print("10 lowest Years values:\n", lowest_years)


# One film of 18k hours and one of 0sec -> remove them because incorrect data
# Many films of under a minute because they're from 1890-1910

# Define minimum and maximum thresholds for reasonable movie runtimes
min_runtime = 0.01  
max_runtime = 10000 


short_movie_indices = df_treated[df_treated['Movie runtime'] < 0.0166667].index
df_treated = df_treated.drop(index=short_movie_indices)
long_movie_indices = df_treated[df_treated['Movie runtime'] > 10000].index
df_treated = df_treated.drop(index=long_movie_indices)

#one movie during the Middle Ages
indices = df_treated[df_treated['Movie release year'] == 1010].index
df_treated = df_treated.drop(index=indices)



df_treated.shape





#https://www.timetoast.com/timelines/us-history-in-the-20th-century
soup = BeautifulSoup(html_code, 'html.parser')


dates = []
titles = []
descriptions = []

entries = soup.find_all('li', class_='list-timeline__item')

for entry in entries:
    date_div = entry.find('div', class_='timeline-item__date')
    date = date_div.time.get_text(strip=True) if date_div and date_div.time else np.nan
    dates.append(date)
    
    title_tag = entry.find('h1', class_='timeline-item__title')
    title = title_tag.get_text(strip=True) if title_tag else np.nan
    titles.append(title)
    
    body_div = entry.find('div', class_='timeline-item__body')
    body = body_div.get_text(strip=True) if body_div else np.nan
    descriptions.append(body)



df_event = pd.DataFrame({'Date': dates,'Title': titles,'Description': descriptions})
df_event['Date'] = pd.to_datetime(df_event['Date'], format="%b %d, %Y")


df_event.head(5)





df_treated.to_csv('../temporary/cleaned_data.csv', index=True, encoding='utf-8')


df_event.to_csv('../temporary/usa_historical_events.csv',index = False)
